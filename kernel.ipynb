{
  "cells": [
    {
      "metadata": {
        "_uuid": "39de6e965330a6f571ef79bb65dd4ff75cacc50b"
      },
      "cell_type": "markdown",
      "source": "**Planet: Understanding the Amazon deforestation from Space challenge**"
    },
    {
      "metadata": {
        "_uuid": "5e06bbc0e79133cb95dbe52800d172a1ad576a1a"
      },
      "cell_type": "markdown",
      "source": "Special thanks to the kernel contributors of this challenge (especially @ekami66 and @saksham219) whose note has inspired me to find a starting point for this notebook."
    },
    {
      "metadata": {
        "_cell_guid": "27b833ed-e7b1-43dd-b903-a9f9e21cb4ed",
        "_uuid": "5d30568abcdc27c8da9fdb9113d2705bd42be9ab"
      },
      "cell_type": "markdown",
      "source": "### Loading required libraries"
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom collections import Counter\nprint(os.listdir(\"../input\"))\nprint(os.listdir('../input/planet-understanding-the-amazon-from-space'))\n%matplotlib inline\nimport matplotlib.image as mpimg\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "120c47b05bb4275b9bcc6d6cc42fb0a0df108070"
      },
      "cell_type": "markdown",
      "source": "**Inspect image labels**\n\n This is a multiclassification problem with 17 unique labels. Looks like we have 40k images for training, and 40k images for testing. The jpegs are on average 15KB, and the tifs are on average 538KB. The JPEGs seem a little on the small side, but TIFFs look like they will retain most of the quality."
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "labels_df = pd.read_csv('../input/planet-understanding-the-amazon-from-space/train_v2.csv')\nprint('images in training set :', labels_df.shape[0])\n#labels_df = labels_df.sample(frac = 1)\nlabels_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c345f71ec740ed09bf42091cd262f68f5c5f8b90",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Print all unique tags\nfrom itertools import chain\nlabels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\nlabels_set = set(labels_list)\nprint(\"There is {} unique labels including {}\".format(len(labels_set), labels_set))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "692bdee2ebbb17d72cd857f4abfa737af2d8a2ac"
      },
      "cell_type": "markdown",
      "source": "So it looks like we are not given much metadata, only the filenames and the corresponding tags. Let's parse these tags so that we can analyze them further."
    },
    {
      "metadata": {
        "_uuid": "4bccabe9fcd4e45411f9be4e565b9b7d86062d8d"
      },
      "cell_type": "markdown",
      "source": "**Visualize what the training dataset looks like.**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "424b640e8b0cf869916f254e328d64c822b79cc2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\n# Histogram of label instances# Histo \nlabels_s = pd.Series(labels_list).value_counts() # To sort them by count\nfig, ax = plt.subplots(figsize=(16, 8))\nsns.barplot(x=labels_s, y=labels_s.index, orient='h')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "106c9f8d-d472-4c0f-92bd-1c42120b703e",
        "_uuid": "082962faa3d171b9d8ccb8551333a94783ffd899",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "counter = Counter([])\nfor tag_list in labels_df['tags'].apply(lambda x:x.split(' ')):\n   counter.update(tag_list)\nlabel_names,count = zip(*counter.items())\nfig = plt.figure(figsize = (15,6))\nax = plt.gca()\nax.bar(np.arange(0,len(label_names),1),count, tick_label = label_names)\nplt.xticks(rotation = 90)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c7439d2c836d434412806ec91fce08e515f7a782"
      },
      "cell_type": "markdown",
      "source": "**Prepare train test data**"
    },
    {
      "metadata": {
        "_cell_guid": "76f07691-8850-434b-a9f4-4323b3af82f8",
        "_uuid": "f7924daa81aae9fafee44adf7b7f3e750a4c8a1c",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "column_df = pd.DataFrame(np.zeros((labels_df.shape[0],17)), columns = label_names)\nlabels_df = pd.concat([labels_df,column_df],axis =1, join = 'inner')\nlabels_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0043a40f-975d-46b8-a732-bd4a51666921",
        "_uuid": "65239ef203720cca6aa119e6b141eee38f5525e2",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "for i,row in enumerate(labels_df['tags']):\n    for category in row.split(' '):\n        labels_df.loc[i,category] = 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "62863695-f4e1-43e2-bd0c-62e253bc48f0",
        "_uuid": "9b56a665024348d3ae4afd47b2943d71916b904b",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "labels_df.to_feather('labels_df.feather')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "18de0c80-5535-4597-93b1-dc75cd5d6be2",
        "_uuid": "253113b53246ddbed8da1dc4391a6165587433a5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "labels_df.drop(['tags'],inplace = True, axis=1)\nlabels_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "003d6a42-a245-47ea-8d04-79e662c99db2",
        "_uuid": "c3df09eff31d9a9914636310016b9bae49d3c4e8",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "labels_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a8dd05df-e9cb-41dd-8b61-02c1ba5d9885",
        "_uuid": "63591f03ddcbf16bda79a231d60c4fc665e24962",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\ntrain_labels, valid_labels = train_test_split(labels_df, test_size = 0.2)\ntrain_labels.shape, valid_labels.shape\ntrain_labels.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "47b18642-f18c-4518-a59f-8206c03691e1",
        "_uuid": "5fafead2245a0d25cfb7605904f1e557906e029d",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "img_path = '../input/planet-understanding-the-amazon-from-space/train-jpg/{}.jpg' \ntrain_images = train_labels['image_name'].apply(lambda x: img_path.format(x)).values\nvalid_images = valid_labels['image_name'].apply(lambda x:img_path.format(x)).values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "adf17be6-c760-4565-8dae-8161efc54723",
        "_uuid": "503c33737d6bc98392234684bca24e756eca105b",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_images.shape, valid_images.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "31f20fd5-c5ca-4f14-ba4c-3746bdcff8b2",
        "_uuid": "464e2e680363a346e39e16b464f43135b3c6d8a0"
      },
      "cell_type": "markdown",
      "source": "### Preparing images (data augmentation)\n\nDefine the dimensions of the image data trained by the network. Recommended resized images could be 32x32, 64x64, or 128x128 to speedup the training.\n\nYou could also use None to use full sized images.\n\nBe careful, the higher the validation_split_size the more RAM you will consume."
    },
    {
      "metadata": {
        "_cell_guid": "7e560c8b-2922-4146-b7a5-083343410e4d",
        "_uuid": "700d8ab777b905428025d56a9093c066722f9f23",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\ndef get_data_iter(data_gen, img_size,label_df, img_list, batch_size, shuffle = True):\n    generator = data_gen.flow_from_directory(directory = '../input/planet-understanding-the-amazon-from-space/train-jpg', target_size = (img_size,img_size), \n                                                             batch_size = batch_size, class_mode = 'sparse', shuffle = shuffle)\n    generator.filenames = img_list\n    generator.classes =  label_df.loc[:,label_df.columns !='image_name'].values\n    generator.samples = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\n    generator.n = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\n    generator.directory = ''\n    generator._set_index_array()\n    return generator",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8003a098-4767-49ae-b70b-a73f67cca204",
        "_uuid": "84b25e295747d65ae1fcda6730e082dfd7f9df12",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data_generator_aug = ImageDataGenerator( rescale = 1./255, horizontal_flip = True,  vertical_flip = True, \n                                        width_shift_range = 0.1, height_shift_range = 0.1, rotation_range = 10)\n\ntrain_generator = get_data_iter(data_generator_aug, 128, train_labels, train_images,64, shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "422011a5-9013-4916-9b3b-f0334ae54baa",
        "_uuid": "b3438d5e1f441fa74b13dd1d3c93b0eeecbdc35f",
        "trusted": true,
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data_generator_no_aug = ImageDataGenerator(rescale = 1./255)\nvalid_generator =  get_data_iter(data_generator_no_aug, 128, valid_labels, valid_images, 2048, shuffle = False) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4dd64262e75e5874bf58b53e1d59893004925b5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_generator_no_aug =  get_data_iter(data_generator_no_aug, 128, train_labels, train_images,64, shuffle = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "48ef4143-4342-48e8-85b4-9d8e2745a965",
        "_uuid": "226d556e454306c23d5099d574616a82ea2f404e",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "t_imgs, t_labels = next(train_generator_no_aug)\n\naug_imgs, aug_labels = next(train_generator)\n\nlabels = train_labels.columns[1:]\n\nfixed_val_imgs,fixed_val_labels = next(valid_generator)\nfixed_val_imgs.shape, fixed_val_labels.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5310ebe7c0f36c321c1f14df949ae384e4d53c1d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "t_imgs.shape, t_labels.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d9c02a1f5a0ad17ff543edf20c5838ff8c1640d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "aug_imgs.shape, aug_labels.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "acaeb6ad3dfb5ae8de0a329636715d27d0b30ef7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def get_label(x):\n    s = np.where(x==1)\n    k = s[0]\n    strings = ', '.join(labels[k])\n    return(strings)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb77e3478cabdd61557b110615e2e8e6e8a7c4a6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = np.random.randint(0,aug_labels.shape[0])\ni = 36\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug1.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "52ebb904ae142d8d0bdf981bf7d371ea65487c22",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = 59\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug2.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "beac087b04e4f7cc1f4b476d30143497a569108f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig,ax = plt.subplots(1,2, figsize = (15,15))\ni = np.random.randint(0,aug_labels.shape[0])\ni = 56\nx = np.apply_along_axis(get_label, 1, aug_labels)\nimage_original = t_imgs[i]\nimage_aug = aug_imgs[i]\nax[0].imshow(image_original)\nax[0].set_title('Original-' + x[i], fontsize =15)\nax[1].imshow(image_aug)\nax[1].set_title('Augmented-' + x[i], fontsize =15)\nfig.savefig('orig_aug3.png')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "83a63f0c-c3d1-4395-83ae-de9e5471887a",
        "_uuid": "fd7e2c308b0af76292feee35b6f0a0a99853e580",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def set_non_trainable_layers(model, range_from, range_to):\n    for i in range(0, len(model.layers)):\n        if range_from <=  i <= range_to:\n            model.layers[i].trainable = False\n        else:\n            model.layers[i].trainable = True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0d06a5fc-81f1-4219-a623-2f342000dbcb",
        "_uuid": "a4cb622e6cb1e06e2194dc4983a8f5d300953688"
      },
      "cell_type": "markdown",
      "source": "# Building model"
    },
    {
      "metadata": {
        "_cell_guid": "0b327b0e-f8b9-40c9-ae60-886d20738064",
        "_uuid": "97716bb202881a662a1b447595cac6b16f32f999",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from tensorflow.python.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, BatchNormalization\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.python.keras.applications.vgg19 import VGG19\n\nimg_size = 128 #64\nnum_classes = 17\n\n\nweights_path = '../input/vgg19-weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model  = VGG19(include_top=False, weights= weights_path,  input_shape= (img_size, img_size, 3) )\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\npredictions = Dense(num_classes, activation = 'sigmoid')(x)\n\nmodel = Model(inputs = base_model.input, outputs = predictions)   #check if input size can be turned off\nset_non_trainable_layers(base_model, 0, 21)\n\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)\nmodel.summary()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "88277859-1a2c-4eb3-a03e-c2158d8e0d2f",
        "_uuid": "0f2f94fadf8d3f09f425494f2a62324fd831fbf9"
      },
      "cell_type": "markdown",
      "source": "### Callbacks for weights saving "
    },
    {
      "metadata": {
        "_cell_guid": "5b41f978-06ef-4d89-86c0-e8eda55d9476",
        "_uuid": "e03b67296b9d024420c24e4d3955d244c92c9bd7",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from tensorflow.python.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweights_path = 'adam_weights.hd5'\ncheckpoint = ModelCheckpoint(weights_path, monitor = 'val_loss', save_best_only = True, save_weights_only = True, mode = 'min', verbose =1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "255b8f29-1cdc-4de8-8d40-5350073cc443",
        "_uuid": "63187133e9397390077e6ddbf687cfe17104186a",
        "_kg_hide-input": true,
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.lrs = []\n        self.batches = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        #lr = self.model.optimizer.lr\n        #self.lrs.append(K.cast(lr, 'float32'))\n\n    def on_train_end(self, logs = None):\n        plt.rcParams[\"figure.figsize\"] = (8,15)\n        plt.plot(np.arange(0,len(self.losses),1)[::5],self.losses[::5], color = 'blue')\n        plt.title('Loss with batches')\n        plt.xlabel('batch')\n        plt.ylabel('mse loss')\n        plt.show()\n        \n    \nclass LRFinder(Callback):  #ignore \n    def __init__(self, max_batches = 5000, base_lr = 1e-4, max_lr = 0.1, lr_step_size = 1e-4):\n        self.max_batches = max_batches\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.lr_step_size = lr_step_size\n        self.lr = 0\n        self.lrs = []\n        self.losses = []\n        self.batches = []\n        \n    def on_batch_end(self, batch, logs={}):\n        current_batch = logs.get('batch')\n        self.batches.append(current_batch)\n        #print(current_batch)\n        '''\n        if current_batch >= self.max_batches or self.lr >= self.max_lr:\n            self.model.stop_training = True\n        else:\n            self.lr = self.lr + (current_batch * self.lr_step_size)\n            K.set_value(self.model.optimizer.lr, self.lr)\n            self.losses.append(logs.get('loss'))\n            self.lrs.append(self.lr)\n    '''\n    def on_train_end(self, logs = None):\n        plt.rcParams[\"figure.figsize\"] = (20,10)\n        plt.plot(self.batches[10::5], self.losses[10::5])\n        plt.xlabel('learning rate')\n        plt.ylabel('loss')\n        plt.title('learning rate finder curve')\n        plt.show()\n\nhistory = LossHistory()\nlrf = LRFinder()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a6762871-e5a4-490c-be14-90b4d4adfe96",
        "_uuid": "b6c1f8047da63b82c873933283f2e7292e500e01"
      },
      "cell_type": "markdown",
      "source": "### Learning rate scheduler for step decay (ignore for adam only for sgd)"
    },
    {
      "metadata": {
        "_cell_guid": "b72134a8-8959-497d-b3eb-9d09802afbee",
        "_uuid": "2c13db6577cc27696212437f240d5f7fd72b8b45",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def step_decay_schedule(initial_lr = 0.01, decay_factor = 0.5, step_size = 2):   #decay_factor =0.5  and step_size = 2 \n    def schedule(epoch):\n        print(initial_lr * (decay_factor ** np.floor(epoch/step_size)))\n        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n    \n    return LearningRateScheduler(schedule)\n\nlr_sched = step_decay_schedule()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0b69c635-7193-4b78-89ab-a2d68b8af9ef",
        "_uuid": "7919fd1e4a5ed9661c672dda1cf906787f1c12ce"
      },
      "cell_type": "markdown",
      "source": "### Reducing learning rate when no improvement in loss "
    },
    {
      "metadata": {
        "_cell_guid": "118c4a47-f4cb-4e5a-9b03-6e291fc25417",
        "_uuid": "1ab39a0ce018126fbef43a20f04aa75c2ed0a9d5",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                              patience=1, min_lr=1e-7, epsilon = 0.001, verbose =1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "716c0daf-3105-418f-b4cc-7a6985d348bb",
        "_uuid": "fd003f64405533e23a360e4472514404bbc34c67"
      },
      "cell_type": "markdown",
      "source": "### define the f2_score metric:"
    },
    {
      "metadata": {
        "_cell_guid": "8a9a0784-343d-4911-940f-97fffee5ac5b",
        "_uuid": "b7ce4214530d6b0ba3c6c245e107f2ab3d1a7d24",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\n\ndef f2_score(y_true, y_preds):\n    beta = 2\n    y_true = K.cast(y_true, \"int32\")\n    y_preds = K.cast(K.round(y_preds), \"int32\") # implicit 0.5 threshold via tf.round\n    y_correct = y_true * y_preds\n    sum_true = tf.reduce_sum(y_true, axis=1)   ##actual positives\n    sum_pred = tf.reduce_sum(y_preds, axis=1)   ##predicted positives\n    sum_correct = tf.reduce_sum(y_correct, axis=1)  ##true positives \n    precision = sum_correct / sum_pred             \n    recall = sum_correct / sum_true\n    f_score = (beta**2 +1) * precision * recall / ((beta**2) * precision + recall)\n    f_score = tf.where(tf.is_nan(f_score), K.zeros_like(f_score), f_score)\n    return tf.reduce_mean(f_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "641e1e42-f6a9-41da-8924-3cc1f66e1502",
        "_uuid": "717e706a41de9bf67fd6936ed76b9014e1161958"
      },
      "cell_type": "markdown",
      "source": "### Define optimizer and compile"
    },
    {
      "metadata": {
        "_cell_guid": "36b45141-08c6-47eb-b824-86944a7122cc",
        "_uuid": "bf7d7f0281d00ae057aa865bb80f210e12929765",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from tensorflow.python.keras.optimizers import SGD, Adam\n\nmodel.compile(optimizer= Adam(lr = 0.001) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 0.01, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f94c30b0-acb7-4384-a97e-30588c96c9d9",
        "_uuid": "240ebd20e48be9cb48325b89e45f56e59b44d8d8"
      },
      "cell_type": "markdown",
      "source": "### Train it"
    },
    {
      "metadata": {
        "_cell_guid": "5eeb021d-47f7-43ff-8c43-c74174c250cf",
        "_uuid": "e8e9eb6a07feac7e99a99f254b758186059c9f08",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.fit_generator(train_generator, steps_per_epoch = 506, epochs = 3 , verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) ,\n                     callbacks = [checkpoint, reduce_lr], workers = 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b9a378c8-1d2b-47d9-86f0-3b2a1ca1b679",
        "_uuid": "3fcbf5097c1252fb43d9bcba8decac5a70a36d72",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "set_non_trainable_layers(model, 0, 16)\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "beaa8f05-29e8-4c0e-85a4-e128917e77fd",
        "_uuid": "ad8d809ec1a13ccd7ccd5240d306eda89bef9816",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.compile(optimizer= Adam(lr=1e-4) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 1e-4, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])\nmodel.fit_generator(train_generator, steps_per_epoch = 506, epochs = 7 , verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) , \n                     callbacks = [checkpoint, reduce_lr], workers = 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4e7df09c-f856-4ecd-9c95-74b48fd13957",
        "_uuid": "7c5bc4ae85fd9fe8e0698c2bda404be0d4209953",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "set_non_trainable_layers(model, 0, 11)\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3ec9bab7-666c-4c09-b047-a193686c047d",
        "_uuid": "cd4b21f9edf81764a3ef28c2e713a4c3520ef1a7",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.compile(optimizer= Adam(lr=1e-5) , loss='binary_crossentropy', metrics = [f2_score])\n#model.compile(optimizer= SGD(lr = 1e-5, momentum = 0.9) , loss='binary_crossentropy', metrics = [f2_score])\nmodel.fit_generator(train_generator, steps_per_epoch = 506, epochs = 13, verbose = 1, validation_data = (fixed_val_imgs,fixed_val_labels) , \n                     callbacks = [checkpoint, reduce_lr, history], workers = 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1cf6c6d3-f639-4406-b2d7-6cea13d4f772",
        "_uuid": "dbe8d5ab230a112756a59096c74c12af50fa96e9",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.rcParams[\"figure.figsize\"] = (8,4)\nplt.plot(np.arange(0,len(history.losses)-1000,80), history.losses[10:-1000:80])\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('training loss curve')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5fd54871-7834-438d-a483-47a7bdb2439e",
        "_uuid": "b2b47b87c018c44976920a1dd4b9f5714df95700",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#model.load_weights('best_weights.hd5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "908eec39-dfad-4c14-aa43-632885dced87",
        "_uuid": "fe27152a1f7005a1853799923b29b2fdb9790da2"
      },
      "cell_type": "markdown",
      "source": "# predicting on test set"
    },
    {
      "metadata": {
        "_cell_guid": "bd0c7453-3887-4461-8b88-51ce54fa4ac8",
        "_uuid": "cec7f893f13bd4c3788e7f0cc3b1c1d2ca8def06",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_dir_path = '../input/planet-understanding-the-amazon-from-space/test-jpg-v2'\n\ntest_images_names = os.listdir(test_dir_path)\ntest_images_paths = [os.path.join(test_dir_path, img_name) for img_name in test_images_names]\n\ntest_data_gen = ImageDataGenerator(rescale = 1./255)\n\nimg_size = 128\ntest_generator = test_data_gen.flow_from_directory(directory = '../input/planet-understanding-the-amazon-from-space/test-jpg-v2', \n                                                   target_size = (img_size,img_size), \n                                                    batch_size = 64,  class_mode = None, shuffle = False)\ntest_generator.filenames = test_images_paths\n#test_generator.samples = label_df.loc[:,label_df.columns !='image_name'].values.shape[0]\ntest_generator.n = len(test_images_paths)\ntest_generator.directory = ''\ntest_generator._set_index_array()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ad585214-dc83-4977-9324-9e2342c61b26",
        "_uuid": "be23f75c2136d4c4cf98050ac340a5b3300135f4",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "rand_images = next(test_generator)\nrand_images.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4ccc9b2f-8c4e-45fc-9496-1d04636e8628",
        "_uuid": "fbdeef82117ce3c186cc2490b8cf7b1090489fa8",
        "scrolled": true,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions = model.predict_generator(test_generator, verbose=1)\npredictions",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a7a936c0-80a6-4edc-8834-1ad94fa128ab",
        "_uuid": "c2b81cdc73565e741c3272271a1008058f1e6164",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions = np.rint(predictions)\npredictions.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0dca24bc-ba06-43b7-86b3-297695ae37bc",
        "_uuid": "acd7d9e3f95650fd4035d6acb553f93f612d22b6",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_images_series = pd.Series([test_image_name.split('.')[0] for test_image_name in test_images_names])\ntest_images_series.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2b3b6ee1-7127-4354-b0bd-a5b1e12245c7",
        "_uuid": "6ae9ae386d12a45cf1065b66abb4d94b7b899db1",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\npreds_df = pd.DataFrame(predictions)\npreds_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1ef922b5-205d-400b-b457-cbd90df6108c",
        "_uuid": "4b93adb06f84b66c05f34af4379703774220848f",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "\ndef get_tags(row):\n    a = np.where(row ==1)\n    tags = np.array(label_names)[a[0]]\n    return ' '.join(tags)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6b0ae638-f851-4527-976b-e829aae01f16",
        "_uuid": "d5837b0fcf652af23c64b0648b8321ab32d60c87",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "tags_series = preds_df.apply(get_tags, axis=1)\ntags_series.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ca293ee7-e242-4cfd-995f-931825f1bd6d",
        "_uuid": "8972a3b57c1f4fe98a89ac1ec5e273b27f0b035b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sub_df = pd.concat([test_images_series,tags_series], axis = 1)\nsub_df.columns = ['image_name', 'tags']\nsub_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee065c76ace70aab9ade12431a8fc089c81bcb0c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'submission.csv'\n\nsub_df.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "493266a4-a9d3-411f-87cc-48ba85a20c48",
        "_uuid": "161545e45c6fe925a8cd245ed4a9ee3c687291aa",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "sub_df.to_csv('submission.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cb9d9176-c5e7-4e8f-a0dc-4fe185174104",
        "_uuid": "42636b6068968be0ae35bd9cde53ba3a3a358ec8"
      },
      "cell_type": "markdown",
      "source": "### Predictions distribution"
    },
    {
      "metadata": {
        "_cell_guid": "be40ca19-c3bf-44e6-9b8c-7a79774c5098",
        "_uuid": "b48f79e62e2199f1968ded9cab085bc9be1946b4",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "counter = Counter([])\nfor tag_list in sub_df['tags'].apply(lambda x:x.split(' ')):\n   counter.update(tag_list)\nlabel_names,count = zip(*counter.items())\nfig = plt.figure(figsize = (15,6))\nax = plt.gca()\nax.bar(np.arange(0,len(label_names),1),count, tick_label = label_names)\nplt.xticks(rotation = 90)\nplt.show()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}